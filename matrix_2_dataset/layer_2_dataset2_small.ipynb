{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epoch = 20\n",
    "# tensorboard_writer = SummaryWriter()\n",
    "T_0 =3\n",
    "T_mult=2\n",
    "eta_min = 1e-6\n",
    "epsilon = 0.01\n",
    "base_matrix = [[[ 2, 2 ],[2,   3 ]]]\n",
    "inv_base_matrix = [[[ 1.5, -1. ],[-1.,   1. ]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModel(\n",
       "  (fc1): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (fc3): Linear(in_features=8, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(4,8)\n",
    "        self.fc3 = nn.Linear(8, 4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 4)   # reshape Variable\n",
    "        x = F.relu(self.fc1(x))\n",
    "#         x = F.dropout(x, 0.1)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "model = BaseModel()\n",
    "model = model.to(torch.double)\n",
    "model = model.to('cuda') \n",
    "model.train()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir):\n",
    "        self.dataset = np.load(root_dir)\n",
    "        print('number of data points', self.dataset.shape[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        x = self.dataset[idx, :,:,0]\n",
    "        y = self.dataset[idx, :,:,1]\n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data points 1000000\n",
      "number of data points 10000\n"
     ]
    }
   ],
   "source": [
    "train_set = CustomDataset('train_set.npy')\n",
    "val_set = CustomDataset('val_set.npy')\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_set,\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=5e-5, weight_decay=1e-7)\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer,T_0,T_mult,eta_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\D_software\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:971: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Step: 7800, Loss: 0.5427, lr: 0.00005000\n",
      "\n",
      "Train Step: 15600, Loss: 0.0551, lr: 0.00003775\n",
      "\n",
      "Train Step: 23400, Loss: 0.0237, lr: 0.00001325\n",
      "\n",
      "Train Step: 31200, Loss: 0.0101, lr: 0.00005000\n",
      "\n",
      "Train Step: 39000, Loss: 0.0021, lr: 0.00004672\n",
      "\n",
      "Train Step: 46800, Loss: 0.0002, lr: 0.00003775\n",
      "\n",
      "Train Step: 54600, Loss: 0.0002, lr: 0.00002550\n",
      "\n",
      "Train Step: 62500, Loss: 0.0001, lr: 0.00001325\n",
      "\n",
      "Train Step: 70300, Loss: 0.0001, lr: 0.00000428\n",
      "\n",
      "Train Step: 78100, Loss: 0.0002, lr: 0.00005000\n",
      "\n",
      "Train Step: 85900, Loss: 0.0001, lr: 0.00004917\n",
      "\n",
      "Train Step: 93700, Loss: 0.0001, lr: 0.00004672\n",
      "\n",
      "Train Step: 101500, Loss: 0.0001, lr: 0.00004282\n",
      "\n",
      "Train Step: 109300, Loss: 0.0001, lr: 0.00003775\n",
      "\n",
      "Train Step: 117100, Loss: 0.0001, lr: 0.00003184\n",
      "\n",
      "Train Step: 125000, Loss: 0.0001, lr: 0.00002550\n",
      "\n",
      "Train Step: 132800, Loss: 0.0001, lr: 0.00001916\n",
      "\n",
      "Train Step: 140600, Loss: 0.0001, lr: 0.00001325\n",
      "\n",
      "Train Step: 148400, Loss: 0.0001, lr: 0.00000818\n",
      "\n",
      "Train Step: 156200, Loss: 0.0001, lr: 0.00000428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_accu = []\n",
    "i = 1\n",
    "for epoch in range(epoch):\n",
    "    for data, target in train_loader:\n",
    "        target = target - torch.tensor(inv_base_matrix)\n",
    "#         print(target)\n",
    "        target = target/epsilon\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        data = data.to('cuda')\n",
    "        target = target.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.mse_loss(output, target.view(-1,4))\n",
    "        loss.backward()\n",
    "        \n",
    "        mse_loss = loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "#         if i % 10 == 0:\n",
    "#             tensorboard_writer.add_scalar(\"Loss/step\", loss, i)\n",
    "        if i % 100 == 0:\n",
    "            print('\\rTrain Step: %d, Loss: %.4f, lr: %.8f'%(i, mse_loss, scheduler.get_lr()[0]), end=\"\")\n",
    "        i += 1\n",
    "    scheduler.step()\n",
    "    print('\\n')\n",
    "torch.save(model.state_dict(), 'small_3.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 421.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.788916144246224e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# analyse a11\n",
    "# target: 1.5- 2.25a+ 1.5b+ 1.5c- d\n",
    "from tqdm import tqdm\n",
    "datapoint=1\n",
    "total_error = 0\n",
    "total_number = 0 \n",
    "for data, target in tqdm(val_loader):\n",
    "    target = target - torch.tensor(inv_base_matrix)\n",
    "    target = target/epsilon\n",
    "    \n",
    "    data, target = Variable(data), Variable(target)\n",
    "#     data = data*epsilon\n",
    "    data = data.to('cuda')\n",
    "#     target = target.to('cuda')\n",
    "    output = model(data)\n",
    "    output = output.detach().to('cpu')\n",
    "#     output = output/epsilon\n",
    "    total_error += torch.sum(torch.abs(output[:,:] - target.view(-1,4)[:,:]))*epsilon\n",
    "    total_number += output.shape[0]*output.shape[1]\n",
    "\n",
    "print(total_error.numpy()/total_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 63.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.093920595790846e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# analyse a11\n",
    "# target: 1.5- 2.25a+ 1.5b+ 1.5c- d\n",
    "from tqdm import tqdm\n",
    "datapoint=1\n",
    "total_error = 0\n",
    "total_number = 0 \n",
    "for data, target in tqdm(val_loader):\n",
    "    target = target - torch.tensor(inv_base_matrix)\n",
    "    target = target/epsilon\n",
    "    \n",
    "    data, target = Variable(data), Variable(target)\n",
    "#     data = data*epsilon\n",
    "    data = data.to('cuda')\n",
    "#     target = target.to('cuda')\n",
    "    output = model(data)\n",
    "    output = output.detach().to('cpu')\n",
    "#     output = output/epsilon\n",
    "    total_error += torch.sum(torch.abs(output[:,:] - target.view(-1,4)[:,:]))*epsilon\n",
    "    total_number += output.shape[0]*output.shape[1]\n",
    "\n",
    "print(total_error.numpy()/total_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 2.9422e-17, -1.0965e-16, -1.0821e-16, -2.9642e-16],\n",
       "         [ 9.5628e-02,  2.9369e-01,  5.3154e-02, -4.4647e-01],\n",
       "         [ 2.5575e-18, -5.1115e-18,  3.6952e-16,  5.6182e-16],\n",
       "         [ 1.5360e+00, -1.2078e+00, -7.5969e-01,  6.3958e-01],\n",
       "         [-3.6153e-01, -4.7281e-02,  4.6443e-01, -3.2432e-01],\n",
       "         [ 3.5525e-01, -1.8960e-01, -6.1029e-01,  1.3732e-01],\n",
       "         [-1.2802e+00,  1.0202e+00,  6.6826e-01, -5.6571e-01],\n",
       "         [-6.5787e-01,  4.8745e-01,  2.9334e-01, -2.2843e-01]], device='cuda:0',\n",
       "        dtype=torch.float64, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-6.6458e-15,  7.9882e-01, -7.6495e-15, -2.4201e-01,  1.0407e+00,\n",
       "          1.2244e+00,  1.9913e-01,  9.9282e-02], device='cuda:0',\n",
       "        dtype=torch.float64, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.6707e-17, -7.5081e-02,  6.4202e-17, -1.1650e+00,  5.8385e-01,\n",
       "          -5.0147e-01,  1.1485e+00,  6.6387e-01],\n",
       "         [ 5.9550e-19, -8.2578e-01, -8.3030e-17,  9.2669e-01,  1.7431e-01,\n",
       "           4.8691e-01, -1.0013e+00, -3.4407e-01],\n",
       "         [ 5.2546e-19, -4.9190e-01,  1.1077e-16,  5.3894e-01, -8.0408e-01,\n",
       "           1.0796e+00, -6.3829e-01, -1.4140e-01],\n",
       "         [ 3.4257e-17,  1.0662e+00,  7.4169e-18, -4.5637e-01,  3.7282e-01,\n",
       "          -6.5138e-01,  5.4483e-01,  1.0231e-01]], device='cuda:0',\n",
       "        dtype=torch.float64, requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.2385,  0.1237,  0.0551, -0.5657], device='cuda:0',\n",
       "        dtype=torch.float64, requires_grad=True)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('small_1.pth'))\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = model.fc1.weight.data.to('cpu').numpy()\n",
    "b1 = model.fc1.bias.data.to('cpu').numpy()\n",
    "W2 = model.fc3.weight.data.to('cpu').numpy()\n",
    "b2 = model.fc3.bias.data.to('cpu').numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3969, -0.5167, -0.0804, -0.5720], dtype=torch.float64)\n",
      "tensor([[ 0.5712, -0.3128],\n",
      "        [-0.5321,  0.3730]], dtype=torch.float64)\n",
      "###\n",
      "1 1.670690992152575e-17\n",
      "4.915572246777594e-34 *a+ -1.831944911715188e-33 *b+ -1.8078282680332953e-33 *c+ -4.952219084900313e-33 *d+ -1.1103024606218899e-31\n",
      "###\n",
      "-1 0.07508124925236073\n",
      "0.007179844582235177 *a+ 0.022050303803059144 *b+ 0.003990901072310622 *c+ -0.033521817800796105 *d+ 0.059976562767422956\n",
      "Used -1\n",
      "###\n",
      "1 6.420168606299503e-17\n",
      "1.6419448795017974e-34 *a+ -3.2816858823977e-34 *b+ 2.3723589388224325e-32 *c+ 3.606988647259131e-32 *d+ -4.911083563715734e-31\n",
      "###\n",
      "-1 1.1650442957350466\n",
      "1.7895587297714999 *a+ -1.4071821670301847 *b+ -0.8850722040309135 *c+ 0.7451388139614773 *d+ -0.2819515753510457\n",
      "###\n",
      "1 0.5838537319640935\n",
      "-0.21107804778365882 *a+ -0.027605063555745754 *b+ 0.2711591315699631 *c+ -0.18935280719842532 *d+ 0.6076357358274985\n",
      "Used 1\n",
      "###\n",
      "-1 0.5014662180337854\n",
      "0.17814358519528556 *a+ -0.09507804949622449 *b+ -0.30603953810079043 *c+ 0.06886303331086208 *d+ 0.6139876686039443\n",
      "Used -1\n",
      "###\n",
      "1 1.148479279277129\n",
      "-1.4702794255124716 *a+ 1.171733707561896 *b+ 0.7674884177461148 *c+ -0.6497029274673678 *d+ 0.22869176911388361\n",
      "Used 1\n",
      "###\n",
      "1 0.6638712029523197\n",
      "-0.4367399243640508 *a+ 0.3236046034609862 *b+ 0.19474319203411566 *c+ -0.1516459265422079 *d+ 0.06591065129886871\n",
      "Used 1\n",
      "[[ 4.91557225e-34 -1.83194491e-33 -1.80782827e-33 -4.95221908e-33]\n",
      " [-7.17984458e-03 -2.20503038e-02 -3.99090107e-03  3.35218178e-02]\n",
      " [ 1.64194488e-34 -3.28168588e-34  2.37235894e-32  3.60698865e-32]\n",
      " [-1.78955873e+00  1.40718217e+00  8.85072204e-01 -7.45138814e-01]\n",
      " [-2.11078048e-01 -2.76050636e-02  2.71159132e-01 -1.89352807e-01]\n",
      " [-1.78143585e-01  9.50780495e-02  3.06039538e-01 -6.88630333e-02]\n",
      " [-1.47027943e+00  1.17173371e+00  7.67488418e-01 -6.49702927e-01]\n",
      " [-4.36739924e-01  3.23604603e-01  1.94743192e-01 -1.51645927e-01]] [-1.11030246e-31 -5.99765628e-02 -4.91108356e-31  2.81951575e-01\n",
      "  6.07635736e-01 -6.13987669e-01  2.28691769e-01  6.59106513e-02] [ 1. -1.  1. -1.  1. -1.  1.  1.]\n",
      "[-2.303420827437702, 1.5407609931603017, 1.5354393783786733, -1.026042876718067] 0.22827392486888365 -0.2384684574680495\n",
      "tensor(0.5714, dtype=torch.float64)\n",
      "tensor(0.5694, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# analyse a11\n",
    "# target: 1.5- 2.25a+ 1.5b+ 1.5c- d\n",
    "datapoint=1\n",
    "\n",
    "for data, target in tqdm(val_loader):\n",
    "    target = target - torch.tensor(inv_base_matrix)\n",
    "    target = target/epsilon\n",
    "    break\n",
    "    \n",
    "input_temp = data.view(-1,4)[datapoint,:].to('cpu')\n",
    "print(input_temp)\n",
    "target_temp = target[datapoint,:].to('cpu')\n",
    "print(target_temp)\n",
    "# a1_matrix = W1*W2[[0],:].T\n",
    "# a1_bias = W2[0,:]*b1\n",
    "a1_matrix = W1\n",
    "a1_bias = b1\n",
    "# print(a1_matrix)\n",
    "# print(a1_bias)\n",
    "sums = 0\n",
    "linear_temp=np.zeros((8,4),dtype=np.double)\n",
    "bias_temp=np.zeros((8,),dtype=np.double)\n",
    "sgn_w2_temp = np.zeros((8,),dtype=np.double)\n",
    "\n",
    "linear_current = [0,0,0,0]\n",
    "bias_current = 0\n",
    "for i in range(8):\n",
    "#     print('W2', W2[0,i])\n",
    "    sgn_w2 = int(W2[0,i]>0)*2-1\n",
    "    abs_w2 = np.abs(W2[0,i])\n",
    "    print('###')\n",
    "    print(sgn_w2,abs_w2)\n",
    "    print(a1_matrix[i,0]*abs_w2,'*a+', \\\n",
    "          a1_matrix[i,1]*abs_w2,'*b+', \\\n",
    "          a1_matrix[i,2]*abs_w2,'*c+', \\\n",
    "          a1_matrix[i,3]*abs_w2,'*d+', \\\n",
    "          b1[i]*abs_w2\n",
    "         )\n",
    "    temp = a1_bias[i]*abs_w2\n",
    "    for j in range(4):\n",
    "        temp = temp+ a1_matrix[i,j]*abs_w2*input_temp[j]\n",
    "        linear_temp[i,j] += (sgn_w2*a1_matrix[i,j]*abs_w2)\n",
    "    bias_temp[i] += sgn_w2*a1_bias[i]*abs_w2\n",
    "    sgn_w2_temp[i]=sgn_w2\n",
    "    if temp>0:\n",
    "        print('Used', sgn_w2)\n",
    "        for j in range(4):\n",
    "            linear_current[j] += W2[0,i]*a1_matrix[i,j]\n",
    "        bias_current += W2[0,i]*a1_bias[i]\n",
    "        sums =sums + sgn_w2*temp\n",
    "#     print('temp',temp)\n",
    "    \n",
    "print(linear_temp, bias_temp, sgn_w2_temp)\n",
    "print(linear_current, bias_current, b2[0])\n",
    "print(sums+b2[0])\n",
    "print(-2.25*input_temp[0]+1.5*input_temp[1]+1.5*input_temp[2]-1*input_temp[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7813/7813 [11:13<00:00, 11.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1345': 417215, '14567': 556714, '1456': 9173, '13457': 8792, '13456': 2602, '135': 622, '1457': 4401, '145': 189, '345': 246, '134567': 21, '1467': 13, '4567': 3, '3457': 7, '457': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# analyse a11\n",
    "# target: 1.5- 2.25a+ 1.5b+ 1.5c- d\n",
    "from tqdm import tqdm\n",
    "statistics = {}\n",
    "for data, target in tqdm(train_loader):\n",
    "    for datapoint in range(data.shape[0]):\n",
    "        input_temp = data.view(-1,4)[datapoint,:].to('cpu')\n",
    "        target_temp = target.view(-1,4)[datapoint,:].to('cpu')\n",
    "    \n",
    "        a1_matrix = W1\n",
    "        a1_bias = b1\n",
    "        sums = 0\n",
    "        linear_temp=[0,0,0,0]\n",
    "        bias_temp=0\n",
    "        temp_arr = ''\n",
    "        for i in range(8):\n",
    "            sgn_w2 = int(W2[0,i]>0)*2-1\n",
    "            abs_w2 = np.abs(W2[0,i])\n",
    "            temp = a1_bias[i]*abs_w2\n",
    "            for j in range(4):\n",
    "                temp = temp+ a1_matrix[i,j]*abs_w2*input_temp[j]\n",
    "            if temp>0:\n",
    "                temp_arr+=chr(ord('0')+i)\n",
    "        if temp_arr not in statistics:\n",
    "            statistics[temp_arr]=0\n",
    "        statistics[temp_arr]+=1\n",
    "print(statistics)\n",
    "#     print('temp',temp)\n",
    "# print(sums+b2[0])\n",
    "# print(linear_temp, bias_temp+b2[0])\n",
    "# print(-2.25*input_temp[0]+1.5*input_temp[1]+1.5*input_temp[2]-1*input_temp[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.23846846  0.12372661  0.05511967 -0.56574118]\n"
     ]
    }
   ],
   "source": [
    "{'1345': 417215, '14567': 556714}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.93277397,  1.3947055 ,  0.9313421 , -0.95536045])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-2.25 +1.5 +1.5 -1\n",
    "#linear_temp, bias_temp, sgn_w2_temp\n",
    "\n",
    "np.sum(np.expand_dims(sgn_w2_temp[[1,4,5,6,7]], axis=1)*linear_temp[[1,4,5,6,7],:],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.022845377660872523"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.215623079807177 -0.2384684574680495"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2866, -0.5810,  0.1632,  0.4102], dtype=torch.float64)\n",
      "tensor([[-0.3902,  0.6857],\n",
      "        [ 0.3151, -0.5391]], dtype=torch.float64)\n",
      "###\n",
      "1 3.425689942326605e-17\n",
      "1.007919865831656e-33 *a+ -3.7563351262661246e-33 *b+ -3.7068848424663126e-33 *c+ -1.0154341641288724e-32 *d+ -2.276634033557734e-31\n",
      "###\n",
      "1 1.066248788082498\n",
      "0.10196288235292301 *a+ 0.3131422284655641 *b+ 0.05667584748630891 *c+ -0.4760522495341581 *d+ 0.8517431183007103\n",
      "Used 1\n",
      "###\n",
      "1 7.416932018537047e-18\n",
      "1.896865066362981e-35 *a+ -3.791184093211186e-35 *b+ 2.740679575852533e-33 *c+ 4.1669917456849816e-33 *d+ -5.673553945872026e-32\n",
      "###\n",
      "-1 0.4563711064433042\n",
      "0.7010058763781349 *a+ -0.5512213440173779 *b+ -0.34670044951463486 *c+ 0.29188574737143463 *d+ -0.11044606018624072\n",
      "Used -1\n",
      "###\n",
      "1 0.37281568452403346\n",
      "-0.13478239936522488 *a+ -0.017627018724781784 *b+ 0.1731467518604734 *c+ -0.12090990014699386 *d+ 0.38800151543387823\n",
      "Used 1\n",
      "###\n",
      "-1 0.6513827684519813\n",
      "0.2314007554914667 *a+ -0.12350224376568601 *b+ -0.39753202591690373 *c+ 0.08945007992344607 *d+ 0.7975432302075222\n",
      "Used -1\n",
      "###\n",
      "1 0.5448312802629286\n",
      "-0.6974912270514791 *a+ 0.5558630334366965 *b+ 0.36409163384364784 *c+ -0.30821494488382783 *d+ 0.10848992367571098\n",
      "###\n",
      "1 0.10230696679335712\n",
      "-0.06730452645112751 *a+ 0.04986962120548315 *b+ 0.030011220839319314 *c+ -0.023369645651305358 *d+ 0.010157269638710633\n",
      "[[ 1.00791987e-33 -3.75633513e-33 -3.70688484e-33 -1.01543416e-32]\n",
      " [ 1.01962882e-01  3.13142228e-01  5.66758475e-02 -4.76052250e-01]\n",
      " [ 1.89686507e-35 -3.79118409e-35  2.74067958e-33  4.16699175e-33]\n",
      " [-7.01005876e-01  5.51221344e-01  3.46700450e-01 -2.91885747e-01]\n",
      " [-1.34782399e-01 -1.76270187e-02  1.73146752e-01 -1.20909900e-01]\n",
      " [-2.31400755e-01  1.23502244e-01  3.97532026e-01 -8.94500799e-02]\n",
      " [-6.97491227e-01  5.55863033e-01  3.64091634e-01 -3.08214945e-01]\n",
      " [-6.73045265e-02  4.98696212e-02  3.00112208e-02 -2.33696457e-02]] [-2.27663403e-31  8.51743118e-01 -5.67355395e-32  1.10446060e-01\n",
      "  3.88001515e-01 -7.97543230e-01  1.08489924e-01  1.01572696e-02] [ 1.  1.  1. -1.  1. -1.  1.  1.]\n",
      "[-0.9652261488819034, 0.9702387975238461, 0.974055074778321, -0.9782979769760327] 0.5526474637133071 -0.5657411764809002\n",
      "tensor(-0.5425, dtype=torch.float64)\n",
      "tensor(-0.5414, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# analyse a11\n",
    "# target: 1.5- 2.25a+ 1.5b+ 1.5c- d\n",
    "from tqdm import tqdm\n",
    "datapoint=0\n",
    "\n",
    "for data, target in tqdm(val_loader):\n",
    "    target = target - torch.tensor(inv_base_matrix)\n",
    "    target = target/epsilon\n",
    "    break\n",
    "    \n",
    "input_temp = data.view(-1,4)[datapoint,:].to('cpu')\n",
    "print(input_temp)\n",
    "target_temp = target[datapoint,:].to('cpu')\n",
    "print(target_temp)\n",
    "# a1_matrix = W1*W2[[0],:].T\n",
    "# a1_bias = W2[0,:]*b1\n",
    "a1_matrix = W1\n",
    "a1_bias = b1\n",
    "# print(a1_matrix)\n",
    "# print(a1_bias)\n",
    "sums = 0\n",
    "linear_temp=np.zeros((8,4),dtype=np.double)\n",
    "bias_temp=np.zeros((8,),dtype=np.double)\n",
    "sgn_w2_temp = np.zeros((8,),dtype=np.double)\n",
    "\n",
    "linear_current = [0,0,0,0]\n",
    "bias_current = 0\n",
    "matrix_ij_idx = 3\n",
    "\n",
    "for i in range(8):\n",
    "#     print('W2', W2[0,i])\n",
    "    sgn_w2 = int(W2[matrix_ij_idx,i]>0)*2-1\n",
    "    abs_w2 = np.abs(W2[matrix_ij_idx,i])\n",
    "    print('###')\n",
    "    print(sgn_w2,abs_w2)\n",
    "    print(a1_matrix[i,0]*abs_w2,'*a+', \\\n",
    "          a1_matrix[i,1]*abs_w2,'*b+', \\\n",
    "          a1_matrix[i,2]*abs_w2,'*c+', \\\n",
    "          a1_matrix[i,3]*abs_w2,'*d+', \\\n",
    "          b1[i]*abs_w2\n",
    "         )\n",
    "    temp = a1_bias[i]*abs_w2\n",
    "    for j in range(4):\n",
    "        temp = temp+ a1_matrix[i,j]*abs_w2*input_temp[j]\n",
    "        linear_temp[i,j] += (sgn_w2*a1_matrix[i,j]*abs_w2)\n",
    "    bias_temp[i] += sgn_w2*a1_bias[i]*abs_w2\n",
    "    sgn_w2_temp[i]=sgn_w2\n",
    "    if temp>0:\n",
    "        print('Used', sgn_w2)\n",
    "        for j in range(4):\n",
    "            linear_current[j] += W2[matrix_ij_idx,i]*a1_matrix[i,j]\n",
    "        bias_current += W2[matrix_ij_idx,i]*a1_bias[i]\n",
    "        sums =sums + sgn_w2*temp\n",
    "#     print('temp',temp)\n",
    "    \n",
    "print(linear_temp, bias_temp, sgn_w2_temp)\n",
    "print(linear_current, bias_current, b2[matrix_ij_idx])\n",
    "print(sums+b2[matrix_ij_idx])\n",
    "#print(-2.25*input_temp[0]+1.5*input_temp[1]+1.5*input_temp[2]-1*input_temp[3])#0\n",
    "#print(1.5*input_temp[0]-1.5*input_temp[1]-input_temp[2]+input_temp[3])#1\n",
    "#print(1.5*input_temp[0]-input_temp[1]-1.5*input_temp[2]+input_temp[3])#2\n",
    "print(-input_temp[0]+input_temp[1]+input_temp[2]-input_temp[3])#3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.01309371276759308"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5526474637133071 -0.5657411764809002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
